Flower:


an error of less than 0.001 after dividing the L1Loss by the batch size, correct?
I believe datapoints is supposed to be dimensions.  So the AutoEncoder has to have 1 layer that's <= 16 neurons wide.


I will save you some time here with matrix operation.

 

im = //PIL image
transformation_test =  transforms.Compose([transforms.ToTensor()])
transformer(im)


import torch
import torch.nn.functional as F
# each row is a 3-dimensional sample 
target = torch.Tensor([[1,3,1],[3,1,5]])
# "scale" the target
min_vals, min_idxes = torch.min(target, 0, keepdim=True)
max_vals, max_idxes = torch.max(target, 0, keepdim=True)
target_scaled = (target - min_vals) / (max_vals-min_vals)
net_output=torch.Tensor([[0.1,0.2,0.3],[0.9,0.8,0.7]])
withtorch = F.l1_loss(net_output, target_scaled)
withformula = torch.mean(torch.abs(target_scaled - net_output))
print(withtorch)
print(withformula)</strong>


A few tips on training
1. Make sure you shuffle your training data before each epoch.

2. Decay the learning rate if you find accuracy saturates. I usually multiply the learning rate by 0.1 at 50% and 75% of the training progress.

3. Make sure your optimizer is defined only once, i.e., it should be defined outside of the training loop. It keeps the momentum of the gradients.

4. Flowers dataset is a bit difficult to train, so here I'm giving you more instructions. You can refer to the vgg (or other) models in this repository <https://github.com/kuangliu/pytorch-cifar/tree/master/models> to design your network, but never copy directly. With 85% training data, a vgg13 from this repo, a SGD optimizer with momentum=0.9, weight_decay=5e-4, (the lr is for you to find, but remember to tune that!), a batch size in the range (16, 100), total epochs < 200, I was able to achieve 82.5% accuracy. You should use data augmentation. Here <https://d1b10bmlvqabco.cloudfront.net/attach/jli25kfo5d92b8/jlel7emjx0e7gu/jnfdvs7l4by2/sample_loader.py>  is the sample code for implementing dataloader with PyTorch and data augmentation.

5. The most direct reference for writing PyTorch should be it's examples. <https://github.com/pytorch/examples> 

6. Remember to add the following line to your code and see if it speeds up.

torch.backends.cudnn.benchmark=True


yes, but only for the flowers. Be very careful not to consume more than 6GB ram, it will be easy to do here.



HW3 (small changes may be made):

Three Meter: MAE < .1% (should be MUCH less if you do it right)

Flowers: >75%

Adult: >82.5%


 Yes cross validation is needed, and if you read the context this is for (look at the readme in the folder for the dataset), why should be obvious. An example that fails is something that has an incredibly different representation after the auto encoder. Some people have gotten such good performance that they may have none.
 

Minimal code length is only for the extra credit, and it's not quite that simple either.


